# 5 分布式搜索

## 5.1 初识ElasticSearch

### 5.1.1 了解ES

是一款非常强大的开源搜索引擎，可以帮助我们从海量的数据中快速搜索到需要的内容。ES结合Kibana，Logstash，Beats也就是elastic stack（ELK），广泛用在日志数据分析，实时监控等领域。

elasticsearch是elastic stack的核心，负责存储，搜索和分析数据。

![](https://shepi-1308499968.cos.ap-chengdu.myqcloud.com/img/elasticstack.png)

### 5.1.2 倒排索引

**① 正向索引**

传统的数据库采用正向索引，在搜索没有索引的字段的时候，只能采用逐行对比的方式来进行比较。这样的效率就很低。

![](https://shepi-1308499968.cos.ap-chengdu.myqcloud.com/img/正向索引.png)



**② 倒排索引**

elasticsearch采用倒排索引：

* 文档（document）：每一条数据就是一个文档
* 词条（term）：文档按照语义分成的词语

![](https://shepi-1308499968.cos.ap-chengdu.myqcloud.com/img/倒排索引.png)

### 5.1.3 es的一些概念

**① 文档**

`elasticsearch`是面向文档存储的，可以是数据库中的一条商品数据，一个订单信息。文档数据会被序列化为`json`格式之后存储在`elasticsearch`中 。

**② 索引**

相同类型文档的集合

![](https://shepi-1308499968.cos.ap-chengdu.myqcloud.com/img/索引.png)

**③ 映射**

索引中文档对于字段的信息，类似表的结构约束。

**④ 概念对比**

![](https://shepi-1308499968.cos.ap-chengdu.myqcloud.com/img/es概念对比.png)



**架构：**

mysql：擅长事务类型的操作，确保数据的安全和一致性

elasticsearch：擅长海量数据的搜索和分析计算



### 5.1.4 安装es、kibbana

```shell
docker run -d \
	--name es \
    -e "ES_JAVA_OPTS=-Xms512m -Xmx512m" \
    -e "discovery.type=single-node" \
    -v es-data:/usr/share/elasticsearch/data \
    -v es-plugins:/usr/share/elasticsearch/plugins \
    --privileged \
    --network es-net \
    -p 9200:9200 \
    -p 9300:9300 \
elasticsearch:7.16.2
```

```shell
docker run -d \
--name kibana \
-e ELASTICSEARCH_HOSTS=http://es:9200 \
--network=es-net \
-p 5601:5601  \
kibana:7.16.2
```



### 5.1.5 安装分词器

es在创建倒排索引的时候需要对文档进行分词，在搜索的时候，需要对用户输入的内容分词。但是默认的分词规则对中文的处理并不是很友好。

```shell
./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.16.2/elasticsearch-analysis-ik-7.16.2.zip
```

**① 分词器的作用**

* 创建倒排索引的时候对文档进行分词
* 用户搜索的时候，对输入的内容进行分词

**② IK分词器的模式**

* `ik_smart`：智能切分，粗粒度
* `ik_max_word`：最细切分，细粒度

**③ IK分词器如何扩展词条和停用词条**

* 利用`config`目录下的`IKAnalyzer.cfg.xml`文件添加扩展词典和停用词典
* 在词典文件`.dict`中添加扩展词条或者停用词条

## 5.2 索引库操作

### 5.2.1 mapping映射属性

mapping是对索引库中文档的约束。

**① mapping属性**

* `type`：字段数据类型，常见的简单类型有：
  * 字符串
    * `txt`：可分词的文本
    * `keyword`：精确值，例如国家、品牌、ip地址，不能拆分，拆了就没有意义了
  * 数值：`long ,integer, short, byte, double, float`
  * 布尔值：`boolean`
  * 日期：`date`
  * 对象：`object`
* `index`：是否是创建索引，默认为`true`
* `analyzer`：使用哪一种分词器
* `properties`：该字段的子字段

**② 创建索引库**

ES中通过Restful请求操作索引库，文档。请求内容使用DSL语句来表示。创建索引库和mapping的DSL语法如下。

```json
PUT /index_base_name
{
    "mapping": {
        "properties": {
            "field_name": {
                "type": "text",
                "analyzer": "ik_smart"
            },
            "field_name": {
                "type": "keyword",
                "index": "false"
            }
            ...
        }
    }
}
```



### 5.2.2 索引库的CRUD

#### 5.2.2.1 查看、删除索引库

```mysql
# 查看索引库
GET /索引库名

# 删除索引库
DELETE /索引库名
```

#### 5.2.2.2 修改索引库

ES强烈建议用户不要修改索引库，一旦出错，就会导致整个索引库不可用。但是可以添加新的字段

```sql
PUT /索引库/_mapping
{
	"properties": {
		"new_field": {
			"type": "text"
		}
	}
}
```

## 5.3 文档操作

### 5.3.1 新增文档

```json
POST /javadong/_doc/1
{
    "info": "不想做咸鱼的咸鱼",
    "email": "dongshaowei1201@gmail.com",
    "name": {
		"firstName": "划水怪"，
        "lastName": "蛇皮"
	}
}
```



### 5.3.2 查询和删除文档

```json
# 查询文档
GET /javadong/_doc/1

# 删除文档
DELETE /javadong/_doc/1	
```



### 5.3.4 修改文档

**① 全量修改**

删除旧文档，添加新文档。这种方式既可以做修改，又可以做新增。

```json
PUT /javadong/_doc/1
{
    "field_name1": "value1",
    "field_name2": "value2"
    ...
}
```

> 如果使用全量修改一个已经存在的文档的某一个字段值，除了这个字段之外，其他的字段将会被删除

**② 增量修改**

修改指定的字段名

```json
POST /javadong/_update/1
{
    "doc": {
        "field_name1": "newValue"
    }
}
```

## 5.4 RestClient操作索引库

ES官方提供了不同语言的客户端，用来操作ES。这些客户端本质上就是用来组装DSL语句，通过HTTP请求发送给ES。

### 5.4.1 创建索引库

### 5.4.2 删除索引库

### 5.4.3 判断索引库是否存在



## 5.5 DSL查询文档

### 5.5.1 DSL查询分类

常见的查询包括：

* 查询所有：查询所有的数据
* 全文检索查询：利用分词器对用户输入的内容做分词，然后去倒排索引库中匹配
  * `match_querry`
  * `multi_mathch_query`
* 精确查询：根据精确词条查询数据，一般是查找`keyword`、数值、日期、`boolean`字段等
  * `ids`
  * `range`
  * `term`
* 地理查询：根据经纬度查询
* 复合查询

**基本的查询语法**：

```json
GET /indexName/_search
{
    "query": {
        "查询类型": {
            "查询条件": "条件值"
        }
    }
}
```



### 5.5.2 全文检索查询

全文检索查询会对用户输入内容进行分词，常用语搜索框中的查询。

**① `mathch`查询**

```json
GET /indexName/_search
{
    "query": {
        "match": {
            "FIELD": "TEXT"
        }
    }
}
```

**② `multi_match`查询**：允许同时查询多个字段

```json
GET /indexName/_search
{
    "query": {
        "multi_match": {
            "query": "TEXT",
            "fields": ["FIELD1", "FIELD2", ...]
        }
    }
}
```

> 随着查询条件的增多，方式2的查询效率明显降低，因此建议使用`copy_to`将需要查询的字段组合到一个字段



### 5.5.3 精准查询

**① `term`**：根据词条精确查询

```json
GET /indexName/_search
{
    "query": {
        "term": {
			"FIELD": {
                "value": "VALUE" 
            }
        }
    }
}
```



**② `range`**：根据值的范围查询

```json
GET /indexName/_search
{
    "query": {
        "range": {
			"FIELD": {
                "gte": "VALUE",
                "lte": "value"
            }
        }
    }
}
```



### 5.5.4 地理坐标查询

常见的使用场景：附近的人

**①** `geo_bounding_box`：查询`geo_point`值落在某一个矩形范围内的所有文档

```json
GET /indexName/_search
{
    "query": {
		"geo_bounding_box": {
            "FIELD": {
                "top_left": {
                	"lat": value,
                	"lon": value	
            	},
                "bottom_right": {
                    "lat": value,
                    "lon": value
                }
            }
        }
    }
}
```



**②** `geo_distance`：查询到指定中心店小于某个距离值的所有文档

```json
GET /indexName/_search
{
    "query": {
		"geo_distance": {
            "distance": "15km",
            "FIELD": "31.41, 121.5"
        }
    }
}
```





### 5.5.5 相关性算分

我们利用`match`查询的时候，文档会根据与词条搜索的相关度打分，返回结果的时候按照相关性降序排列。

`elasticsearch`中相关性打分的算法：

* `TF-IDF`：`5.0`之前，会随着词频的增加而增加
* `BM25`：`5.0`之后，随着词频的增大而增大，但是会有一个稳态值

### 5.5.6 Function Score Query

可以修改文档的相关性算分，得到新的算分排序

```json
GET /hotel/_search
{
  "query": {
    "function_score": {
      "query": {
        "match": {
          "all": "外滩"
        },
        "function": [
          {
            "filter": {
              "term": {
                "id": "1"
              }
            },
            "weight": 10
          }
        ],
        "boost_mode": "multiply"
      }
    }
  }
}
```

> 牢记三要素：
>
> * 过滤条件：需要加分的文档
> * 算分函数：如何计算function score
> * 加权方式：function score 和 queryscore如何运算

### 5.5.6 Boolean查询

布尔查询是一个或者多个子查询的语句的组合：

* `must`：必须匹配每一个子查询，类似于`&`
* `should`：选择性匹配子查询，类似于`|`
* `must_not`：必须不匹配，类似于`!`
* `filter`：必须匹配但是不参与算分

**一个 例子**：

```json
GET /hotel/_search
{
    "query": {
        "bool": {
            "must": [{"term": {"city": "上海"}}],
            "should": [
                {"term": {"brand": "皇冠假日"}}，
                {"term": {"brand": "华美达"}}
            ],
    		"must_not": [{"range": {"price": {"lte": 500}}}],
			"filter": [{"range": {"score": {"gte": 45}}}]
        }
    }
}
```





## 5.6 搜索结果处理

### 5.6.1 排序

`elasticsearch`支持对搜索结果的排序，默认是按照搜索结果的算分来排序的。可以排序的字段有`keyword`, 数值类型、地理坐标类型、日期类型等。

```json
GET /indexName/_search
{
    "query": {
        "match_all": {}
    },
    "sort": [{"FIELD": "desc"}] // 排序底端和排序方式ASC/DESC
}
```



### 5.6.2 分页

`elasticsearch`默认情况下只返回top10的数据，如果想要查询更多的数据需要修改分页的参数。

`elasticsearch`通过修改`from`,`size`参数来控制要返回的分页结果。

```json
GET /hotel/_search
{
    "query": {
        "match_all": {}
    },
    "from": 990, // 分页开始的位置，默认为0
    "size": 10,
    "sort": [{"price": "asc"}]
}
```

**深度分页问题**

对于分布式的ES，会面临深度分页的问题，例如将`price`排序之后，获取`990-999`的数据：

* 首先在每一个数据分片中排序并且查询前1000条文档
* 将所有的节点聚合，在内存中重新排序选出前1000条文档
* 最后从这1000条文档中，选取`990-999`的文档

> ES设定查询结果集的上限是10000

**深度分页的解决方案：**

* `search after`：分页的时候需要排序，原理是从上一次的排序值开始，查询下一页数据
* `scroll`：将排序数据形成快照，保存在内存中



### 5.6.3 高亮

在搜索结果中将搜索关键字突出显示

**① 原理**	

* 给搜索结果中的关键字使用标签标记
* 在页面中给标签添加css样式

**② 语法**

```json
GET /hotel/_search
{
    "query": {
        "match": { // 只能使用带关键字的搜索
            "FIELD": "TEXT"
        }
    },
    "highlight": {
        "fields": { // 指定需要高亮显示的字段
            "FIELD": {
                "require_field_match":
                "pre_tags": "<em>", // 用来标记高亮字段的前置标签
                "post_tags": "</em>" // 用来标记高亮字段的后置标签
            }
        }
    }
}
```

> 默认情况下，ES搜索字段必须和高亮字段一致。可以在字段中设置是否需字段匹配



## 5.7 RestClient查询文档

### 5.7.1 快速入门

```java
@Test
public void testMatchAll() throws IOException{
    // 准备request
    SearchRequest req = new SearchRequest("hotel");
    // 组织DSL参数
    req.source()
        .query(QueryBuilers .matchAllQuery());
    // 发送请求
    Search resp = client.search(request, RequestOptions.DEFAULT);
}
```



### 5.7.2 排序和分页

```java
// 分页
req.source().from(0).size(5);

// 排序
rea.source().sort("price", SortOrder.ASC);
```



### 5.7.3 高亮

```java
req.source.highlighter(new HignlighterBuilder()
    .field("name")
    .requireFieldMatch(false) // 是否需要与查询字段匹配
);
```

高亮结果的获取：

```java
// 获取source
HotelDoc doc = JSON.parseObject(hit.getSourceAsString, HotelDoc.class);

Map<String, HighlightField> highlight = hit.getHighlightFields();
if (!CollectionUtils.isEmpty(highlight)) {
    // 获取高亮的片段
    HighlightField highlightField = HighlightFields.get("name");
    String name = highlightField.getFragments()[0].string();
    hotelDoc.setName(name);
}

```



## 5.8 黑马旅游网案例



## 5.9 数据聚合

### 5.9.1 聚合的种类

聚合可以实现对文档数据的统计、分析、运算。常见的聚合有三类：

* 桶聚和：用来对文档做分组
  * `TermAggregation`：按照文档的字段值分组
  * `Date Histogram`：按照日期阶梯分组，例如一个月一组等
* 度量聚合：用来计算一些统计值
  * `avg`
  * `max`
  * `min`
  * `stats`：同时求出常见的统计数据
* `pipleline`聚合：其他聚合的结果为基础做出聚合



### 5.9.2 DSL实现数据聚合

#### 5.9.2.1 桶聚和

```json
# 聚合功能,自定义排序规则
GET /hotel/_search
{
  "size": 0,
  "aggs": {
    "brandAggs": {
      "terms": {
        "field": "brand",
        "size": 10,
        "order": {
          "_count": "asc"
        }
      }
    }
  }
}
```

> 聚合的三要素：
>
> * 聚合名称
> * 聚合类型
> * 聚合字段

#### 5.9.2.2 度量聚合

获取每一个品牌的用户评分的最小值，最大值，平均值



### 5.9.3 RestAPI实现聚合



## 5.10 自动补全

### 5.10.1 自定义分词器

`elasticsearch`中分词器的组成包含三个部分：

* `character filters`：在`tokenizer`之前对文本进行处理，例如删除字符，替换字符等
* `tokenizer`：将文本按照一定的规则切割成词条，例如`keyword`就是不分词
* `tokenizer filter`：将`tokenizer`输出的词条做进一步的处理，例如大小写转换、同义词处理、拼音处理等等

> 为了避免搜索到同音字，搜索是不要使用拼音分词器

### 5.10.2 自动补全

`elasticsearch`提供了`Completion Suggestser`查询来实现自动补全功能。这个查询会匹配以用户输入内容开头的词条并且返回。为了提高补全查询的效率，对于文档中字段的类型有一些约束：

* 参与补全查询的字段必须是`completion`类型
* 字段的内容一般是用来补全的多个词条形成的数组 

### 5.10.3 实现`hotel`索引库的自动补全

实现思路：

* 修改`hotel`索引库的结构，设置自定义拼音分词器
* 修改索引库的`name`，`all`字段，使用自定义分词器
* 索引库添加一个新的字段`suggestion`，类型为`completion`，使用自定义的拼音发分词器
* 给`HotelDoc`类添加`suggestion`字段，内容包含`brand`，`business`
* 重新导入数据到`hotel`库



## 5.11 数据同步

### 5.11.1 数据同步问题分析

`elasticsearch`中的酒店数据来自于`mysql`数据库，因此当`mysql`数据库发生变化的时候，`elasticsearch`也许跟着改变，这个就是两个数据之间的**数据同步**。

**① 方案一**

![](https://shepi-1308499968.cos.ap-chengdu.myqcloud.com/img/同步调用.png)

* 优点：实现简单粗暴

* 缺点：业务耦合程度比较高

  

**② 方案二**

![](https://shepi-1308499968.cos.ap-chengdu.myqcloud.com/img/异步通知.png)

* 优点：低耦合，实现难度一般
* 缺点：依赖mq的可靠性

**③ 方案三**

![](https://shepi-1308499968.cos.ap-chengdu.myqcloud.com/img/监听binlog.png)

* 优点：完全解出服务器之间的耦合
* 缺点：开启binlog增加数据库的负担，实现复杂度比较高



## 5.12 集群

### 5.12.1 搭建ES集群

单机的`elasticsearch`做数据存储，面临两个问题：

* 海量数据问题：将索引库从逻辑上拆成n个分片`shard`，存储到多个节点`Node`
* 单点故障问题：将分片数据备份放在不同的节点

ES集群之中不同的节点的职责：

![](https://shepi-1308499968.cos.ap-chengdu.myqcloud.com/img/ES集群中不同节点的职责.png)



### 5.12.2 集群脑裂问题

默认情况下，每一个节点都是`master eligible`节点，因此一旦master节点出现故障，其他节点会选举一个主节点。当出节点和其他节点的通信出现网络故障的时候，可能发生脑裂问题。



**分布式查询**

`elasticsearch`的查询分为两个阶段：

* `scatter phase`：分散阶段，`coordinating node`会将请求分发到每一个分片
* `gather phase`：聚集阶段，`coordinating node`汇总data node的搜索结果，并处理为最终结果集返回给用户



**分布式新增如何确定分片？**

* `coordinating node`根据`id`做哈希运算，得到结果对`shard`数量取余，余数就是对应的分片

### 5.12.3 集群故障转移

集群的`master`节点会监控集群中的节点状态，如果发现有节点宕机，就会立即将宕机节点的分片数据迁移到其他的节点，确保数据安全，这个就是**故障转移**。
